{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "## Clasificación de Sonidos Urbanos\n",
    "\n",
    "**Universidad del Valle de Guatemala**\\\n",
    "**Facultad de Ingeniería**\\\n",
    "**Departamento de Ciencias de la Computación**\\\n",
    "**Deep Learning**\n",
    "\n",
    "---\n",
    "### Integrantes:\n",
    "- Diego Leiva\n",
    "- Pablo Orellana\n",
    "- Maria Marta Ramirez\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualización\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import platform\n",
    "\n",
    "# Advertencias\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # Ignorar advertencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_PATH = 'data/UrbanSound8K/audio/'\n",
    "\n",
    "# Obtencion de metadatos\n",
    "metadata = pd.read_csv('data/UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "files = metadata['slice_file_name'].values\n",
    "labels = metadata['classID'].values\n",
    "folds = metadata['fold'].values\n",
    "classes = metadata['class'].values\n",
    "\n",
    "# Creacion de directorios\n",
    "paths = [\n",
    "    os.path.join(AUDIO_PATH + f\"fold{fold}\", file) for fold, file in zip(folds, files)\n",
    "]\n",
    "\n",
    "# Crear y ordenar el diccionario de mapeo classID -> class\n",
    "class_mapping = dict(sorted(metadata[['classID', 'class']].drop_duplicates().set_index('classID')['class'].to_dict().items()))\n",
    "\n",
    "# Ver el mapeo resultante\n",
    "print(\"-\"*15, \" Mapeo de clases \", \"-\"*15)\n",
    "for key, value in class_mapping.items():\n",
    "    print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuracion de PyTorch CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semilla para reproducibilidad\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Configuración de determinismo\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device_info = \"\"\n",
    "\n",
    "# Configuración de dispositivo\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    device_info = f'{torch.cuda.get_device_name(0)}'\n",
    "else:\n",
    "    device_info = f\"{platform.processor()}\"\n",
    "\n",
    "print(f\"Device: {device_info}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset y Dataloader de Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset():\n",
    "    def __init__(self, paths, labels, train=True):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.audio_length = 160000  # 4 segundos de audio\n",
    "        self.train = train\n",
    "\n",
    "        # Definir transformaciones con parámetros ajustados\n",
    "        self.mel_spec = torchaudio.transforms.MelSpectrogram(\n",
    "            sample_rate=22050,\n",
    "            n_fft=2048,\n",
    "            win_length=1024, \n",
    "            hop_length=512,  \n",
    "            n_mels=128,     \n",
    "            f_min=20,\n",
    "            f_max=11025  # sample_rate/2\n",
    "        )\n",
    "\n",
    "        # Masking de la señal de audio\n",
    "        self.time_masking = torchaudio.transforms.TimeMasking(time_mask_param=30)\n",
    "        self.freq_masking = torchaudio.transforms.FrequencyMasking(freq_mask_param=20)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.paths[idx]\n",
    "        waveform, _ = torchaudio.load(file, normalize=True)\n",
    "        mono = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "        temp = torch.zeros([1, self.audio_length])\n",
    "        if mono.numel() < self.audio_length:\n",
    "            temp[:, :mono.numel()] = mono\n",
    "        else:\n",
    "            temp = mono[:, :self.audio_length]\n",
    "\n",
    "        # Asignar audio mono \n",
    "        audio_mono = temp\n",
    "\n",
    "        # Obtener espectrograma de Mel\n",
    "        mel_spectrogram = self.mel_spec(audio_mono)\n",
    "\n",
    "        # Aplicar masking en training\n",
    "        if self.train:\n",
    "            mel_spectrogram = self.time_masking(mel_spectrogram)\n",
    "            mel_spectrogram = self.freq_masking(mel_spectrogram)\n",
    "            \n",
    "        # Normalización más robusta\n",
    "        mel_spectrogram_norm = (mel_spectrogram - mel_spectrogram.mean()) / (mel_spectrogram.std() + 1e-7)\n",
    "\n",
    "\n",
    "        feature_dict = {\n",
    "            'feature_vector': mel_spectrogram_norm[0].permute(1, 0).clone().detach(),\n",
    "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "        return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_data(data):\n",
    "    # Inicializar listas de features y labels\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterar sobre los datos\n",
    "    for element in data:\n",
    "        # Extraer feature y label\n",
    "        feature = element[\"feature_vector\"].to(device)\n",
    "        label = element[\"label\"].to(device)\n",
    "\n",
    "        # Agregar a las listas\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Realizar padding de los features y convertir labels a tensor\n",
    "    feature = nn.utils.rnn.pad_sequence(features, batch_first=True, padding_value=0.)\n",
    "    labels = torch.stack(labels).long()  # Asegurar que labels sea Long\n",
    "\n",
    "    return feature, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioLSTM(nn.Module):\n",
    "    def __init__(self, feature_size, out_features, hidden_layers, layers, dropout):\n",
    "        super().__init__()\n",
    "        self.n_hidden = hidden_layers\n",
    "        self.n_layers = layers\n",
    "        self.n_feature = feature_size\n",
    "\n",
    "        # Capa LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.n_feature,\n",
    "            hidden_size=self.n_hidden,\n",
    "            num_layers=self.n_layers,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Aplicar mecanismo de atención\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(self.n_hidden * 2, self.n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(self.n_hidden, 1)\n",
    "        )\n",
    "\n",
    "        # Capa de dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Primer capa lineal con batch normalization\n",
    "        self.fc1 = nn.Linear(self.n_hidden * 2, self.n_hidden)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(self.n_hidden)\n",
    "        \n",
    "        # Segunda capa lineal con batch normalization\n",
    "        self.fc2 = nn.Linear(self.n_hidden, int(self.n_hidden/2))\n",
    "        self.batch_norm2 = nn.BatchNorm1d(int(self.n_hidden/2))\n",
    "        \n",
    "        # Capa de salida\n",
    "        self.fc3 = nn.Linear(int(self.n_hidden/2), out_features)\n",
    "\n",
    "    # Attention mechanism\n",
    "    def attention_net(self, lstm_output):\n",
    "        # Obtener el tamaño de la secuencia \n",
    "        attention_weights = self.attention(lstm_output)\n",
    "        attention_weights = F.softmax(attention_weights, dim=1)\n",
    "\n",
    "        # Aplicar atención a la salida de la LSTM\n",
    "        context_vector = torch.sum(attention_weights * lstm_output, dim=1)\n",
    "        return context_vector\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, x, hidden):\n",
    "        # X shape -> (batch_size, sequence_length, n_features)\n",
    "        # Salida de la capa LSTM\n",
    "        l_out, l_hidden = self.lstm(x, hidden)\n",
    "\n",
    "        # Aplicar mecanismo de atención\n",
    "        attn_out = self.attention_net(l_out)\n",
    "\n",
    "        # Out shape -> (batch_size, sequence_length, n_hidden*direcction)\n",
    "        # Aplicar Dropout a la salida de la capa LSTM\n",
    "        out = self.dropout(attn_out)\n",
    "        \n",
    "        identity = out\n",
    "        # Paso a través de la primera capa lineal\n",
    "        out = self.fc1(out) # Tomar la salida de la capa LSTM con atención\n",
    "        out = self.batch_norm1(out)  # Aplicar batch normalization\n",
    "\n",
    "        # Aplicar función de activación ReLU\n",
    "        out = F.relu(out)\n",
    "\n",
    "        # Paso a través de la segunda capa lineal\n",
    "        out = self.fc2(out)\n",
    "        out = self.batch_norm2(out)\n",
    "\n",
    "        # Aplicar función de activación ReLU\n",
    "        out = F.relu(out)\n",
    "\n",
    "        # Aplicar dropout\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        # Paso a través de la capa de salida\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        # Retornar el output y el hidden state\n",
    "        return out, l_hidden\n",
    "    \n",
    "\n",
    "    # Inicializar hidden state\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Obtener pesos de la primera capa\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        # Inicializar hidden state con ceros\n",
    "        hidden = (weight.new(self.n_layers * 2, batch_size, self.n_hidden).zero_().to(device),\n",
    "                  weight.new(self.n_layers * 2, batch_size, self.n_hidden).zero_().to(device))\n",
    "        \n",
    "        # Retornar hidden state\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(state, path):\n",
    "    torch.save(state, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, epoch, optimizer, device):\n",
    "    # Inicializar lista de perdidas, accuracy, labels y predicciones\n",
    "    losses = []\n",
    "    labels = []\n",
    "    predictions = []\n",
    "\n",
    "    # Establecer modelo en modo de entrenamiento\n",
    "    model.train()\n",
    "\n",
    "    # Crear barra de progreso\n",
    "    loop = tqdm(data_loader)\n",
    "\n",
    "    # Iterar sobre los datos\n",
    "    for batch_idx, (data, target) in enumerate(loop):\n",
    "        # Enviar datos al dispositivo\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Limpiar gradientes\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Inicializar hidden state y output\n",
    "        output, _ = model(data, model.init_hidden(data.size(0)))\n",
    "        \n",
    "        # Calcular perdida\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward() # Backpropagation\n",
    "\n",
    "        # Optimizar\n",
    "        optimizer.step()\n",
    "\n",
    "        # Agregar perdida\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Obtener mayor valor de output\n",
    "        winners = output.argmax(dim=1)\n",
    "        \n",
    "        # Agregar labels y predicciones\n",
    "        labels += torch.flatten(target).cpu().tolist()\n",
    "        predictions += torch.flatten(winners).cpu().tolist()\n",
    "\n",
    "        # Calcular accuracy del batch\n",
    "        batch_accuracy = (winners == target).sum().float() / float(target.size(0))\n",
    "\n",
    "        # Actualizar barra de progreso\n",
    "        loop.set_description(f\"TRAIN -> Epoch {epoch} | Batch: {batch_idx+1}/{len(data_loader)} | Loss: {loss.item():.4f} | Accuracy: {batch_accuracy:.4f}\")\n",
    "\n",
    "    # Obtener promedio de perdidas y accuracy total del epoch\n",
    "    total_loss = np.mean(losses)\n",
    "    total_accuracy = np.mean(np.array(labels) == np.array(predictions))\n",
    "\n",
    "    # Obterner reporte de clasificacion de la epoch\n",
    "    train_report = classification_report(labels, predictions, output_dict=True)\n",
    "    # Obtener matriz de confusion de la epoch\n",
    "    train_confusion_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "    # Imprimir métricas finales usando tqdm.write\n",
    "    tqdm.write(f\"TRAIN -> Epoch {epoch} | Final Loss: {total_loss:.4f} | Final Accuracy: {total_accuracy:.4f}\")\n",
    "\n",
    "    # Retornar perdida, accuracy, reporte y matriz de la epoca\n",
    "    return total_loss, total_accuracy, train_confusion_matrix, train_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de Validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(data_loader, model, device):\n",
    "    # Inicializar lista de perdidas, accuracy, labels\n",
    "    losses = []\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    \n",
    "    # Configurar modelo en modo de evaluacion\n",
    "    model.eval()\n",
    "\n",
    "    # Sin actualizar gradientes\n",
    "    with torch.no_grad():\n",
    "        # Crear barra de progreso\n",
    "        loop = tqdm(data_loader)\n",
    "\n",
    "        # Iterar sobre los datos\n",
    "        for batch_idx, (data, target) in enumerate(loop):\n",
    "            # Enviar datos al dispositivo\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Inicializar hidden state y output\n",
    "            output, _ = model(data, model.init_hidden(data.size(0)))\n",
    "\n",
    "            # Calcular perdida\n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "            # Agregar perdida\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Obtener mayor valor de output\n",
    "            winners = output.argmax(dim=1)\n",
    "\n",
    "            # Agregar lables y predicciones\n",
    "            labels += torch.flatten(target).cpu()\n",
    "            predictions += torch.flatten(winners).cpu()\n",
    "\n",
    "            # Calcular accuracy\n",
    "            batch_accuracy = (winners == target).sum().float() / float(target.size(0))\n",
    "\n",
    "            loop.set_description(f\"VALIDATE -> Batch: {batch_idx+1}/{len(data_loader)} | Accuracy: {batch_accuracy:.4f}\")\n",
    "\n",
    "    # Calcular accuracy total de toda la época de validación\n",
    "    total_accuracy = np.mean(np.array(labels) == np.array(predictions))\n",
    "    # Obtener promedio de perdidas de la época de validación\n",
    "    total_loss = np.mean(losses)\n",
    "\n",
    "    # Obtener reporte de clasificación de la época de validación\n",
    "    val_report = classification_report(labels, predictions, output_dict=True)\n",
    "    # Obtener matriz de confusión de la época de validación\n",
    "    val_confusion_matrix = confusion_matrix(labels, predictions)\n",
    "\n",
    "    # Imprimir métricas finales usando tqdm.write\n",
    "    tqdm.write(f\"VALIDATE -> Final Loss: {total_loss:.4f} | Final Accuracy: {total_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "    # Retornar perdida, accuracy, reporte y matriz de la época de validación\n",
    "    return total_loss, total_accuracy, val_confusion_matrix, val_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuracion inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes\n",
    "EPOCHS = 50 # Numero de epocas\n",
    "OUT_FEATURE = 10 # Numero de clases\n",
    "SCHEDULER_PATIENCE = 5 # Paciencia para el scheduler\n",
    "FEATURE_SIZE = 128 # Tamaño de los features (n_mels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop Principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este loop se hacen los splits train-test para los 10 Folds, de esta manera se entrena el modelo con 9 Folds y se Valida con el Sobrante. Obteniendo metricas de rendimiento para la mejor epoca en cada Fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave One Group Out Cross Validation\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Lista de diccionarios de Rendimiento de cada fold\n",
    "folds_performance = []\n",
    "\n",
    "# Loop de entrenamiento por epocas y folds\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(logo.split(paths, labels, folds)):\n",
    "    \n",
    "    # Diccionario de resultados del fold actual\n",
    "    results = {\n",
    "        'fold': fold_idx + 1,\n",
    "        'train_losses': [],\n",
    "        'val_losses': [],\n",
    "        'train_accuracies': [],\n",
    "        'val_accuracies': [],\n",
    "        'train_report': None,\n",
    "        'val_report': None,\n",
    "        'train_matrix': None,\n",
    "        'val_matrix': None,\n",
    "        'best_accuracy': 0,\n",
    "        'best_epoch': 0\n",
    "    }\n",
    "\n",
    "    # Imprimir separador si no es el primer fold\n",
    "    if fold_idx > 0:\n",
    "        print(f\"\\n\")\n",
    "    \n",
    "    print(\"-\"*15, f\" FOLD {fold_idx+1} \", \"-\"*15)\n",
    "\n",
    "    # Dividir datos en train y validation sets\n",
    "    train_paths = [paths[i] for i in train_idx]\n",
    "    val_paths = [paths[i] for i in val_idx]\n",
    "    train_labels = [labels[i] for i in train_idx]\n",
    "    val_labels = [labels[i] for i in val_idx]\n",
    "\n",
    "    # Crear datasets\n",
    "    train_dataset = AudioDataset(train_paths, train_labels, train=True)\n",
    "    val_dataset = AudioDataset(val_paths, val_labels, train=False)\n",
    "\n",
    "    # Crear dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=False, collate_fn=collate_data)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=collate_data)\n",
    "\n",
    "    # Entrenamiento del Modelo\n",
    "    model = AudioLSTM(feature_size=FEATURE_SIZE, \n",
    "                      out_features=OUT_FEATURE, \n",
    "                      hidden_layers=256, \n",
    "                      layers=2, \n",
    "                      dropout=0.3).to(device)\n",
    "    \n",
    "    # Crear optimizador AdamW y scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-3) # Peso decaimiento\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', patience=SCHEDULER_PATIENCE, factor=0.1) # Reducir tasa de aprendizaje\n",
    "\n",
    "    # Loop de entrenamiento\n",
    "    for epoch in range(EPOCHS):\n",
    "        \n",
    "        # Entrenar modelo y obtener perdidas y accuracy\n",
    "        epoch_train_loss, epoch_train_acc, epoch_train_matrix, epoch_train_report = train_model(train_loader, model, epoch, optimizer, device)\n",
    "\n",
    "        # Validar modelo y obtener accuracy\n",
    "        epoch_val_loss, epoch_val_acc, epoch_val_matrix, epoch_val_report = validate(val_loader, model, device)\n",
    "\n",
    "        # Guardar perdidas y accuracies del epoch actual\n",
    "        results['train_losses'].append(epoch_train_loss)\n",
    "        results['val_losses'].append(epoch_val_loss)\n",
    "        results['train_accuracies'].append(epoch_train_acc)\n",
    "        results['val_accuracies'].append(epoch_val_acc)\n",
    "        \n",
    "        # Actualizar el scheduler y guardar el mejor modelo\n",
    "        scheduler.step(epoch_train_acc)\n",
    "        \n",
    "        # Guardar el mejor modelo y metricas de desempeño para el fold actual\n",
    "        if epoch_val_acc > results['best_accuracy']:\n",
    "            # Resetear contador de paciencia\n",
    "            no_improvement = 0\n",
    "\n",
    "            # Actualizar mejor accuracy y epoch\n",
    "            results['best_accuracy'] = epoch_val_acc\n",
    "            results['best_epoch'] = epoch\n",
    "            \n",
    "            # Actualizar reportes y matrices\n",
    "            results['train_report'] = epoch_train_report\n",
    "            results['val_report'] = epoch_val_report\n",
    "            results['train_matrix'] = epoch_train_matrix\n",
    "            results['val_matrix'] = epoch_val_matrix\n",
    "\n",
    "            # Guardar mejor modelo hasta ahora\n",
    "            save_model({'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'models/lstmv2_fold{fold_idx + 1}.pth')\n",
    "\n",
    "    # Terminar fold y guardar resultados\n",
    "    folds_performance.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metricas Estadisticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar los mejores epochs y accuracies de cada fold\n",
    "print(\"-\"*15 ,f\" FINAL RESULTS \", \"-\"*15)\n",
    "for fold_result in folds_performance:\n",
    "    print(f\"    Fold {fold_result['fold']} - Best Epoch: {fold_result['best_epoch']}, Best Accuracy: {fold_result['best_accuracy']:.4f}\")\n",
    "\n",
    "# Calcular el promedio de los mejores accuracies\n",
    "best_accuracies = [fold_result['best_accuracy'] for fold_result in folds_performance]\n",
    "mean_accuracy = np.mean(best_accuracies)\n",
    "std_accuracy = np.std(best_accuracies)\n",
    "print(f\"\\nAverage of Best Accuracies: {mean_accuracy:.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {std_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab10')\n",
    "colors = cmap(np.linspace(0, 1, len(best_accuracies)))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(best_accuracies) + 1), best_accuracies, color=colors, edgecolor='black')\n",
    "plt.axhline(y=mean_accuracy, color='black', linestyle='--', label=f'Average Accuracy: {mean_accuracy:.4f}', linewidth=2)\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Best Accuracy')\n",
    "plt.title('Best Accuracy per Fold')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies por clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer las precisiones por clase y fold\n",
    "num_classes = 10 # Numero de clases\n",
    "num_folds = len(folds_performance)\n",
    "class_accuracies_train = np.zeros((num_folds, num_classes))\n",
    "class_accuracies_val = np.zeros((num_folds, num_classes))\n",
    "\n",
    "for i, fold_result in enumerate(folds_performance):\n",
    "    train_report = fold_result['train_report']\n",
    "    val_report = fold_result['val_report']\n",
    "    for class_idx in range(num_classes):\n",
    "        class_label = str(class_idx)\n",
    "        if class_label in train_report:\n",
    "            class_accuracies_train[i, class_idx] = train_report[class_label]['precision']\n",
    "        if class_label in val_report:\n",
    "            class_accuracies_val[i, class_idx] = val_report[class_label]['precision']\n",
    "            \n",
    "# Calcular el promedio por clase para entrenamiento y validación\n",
    "mean_class_accuracies_train = np.mean(class_accuracies_train, axis=0)\n",
    "mean_class_accuracies_val = np.mean(class_accuracies_val, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el layout de los subplots\n",
    "fig, axs = plt.subplots(2, 5, figsize=(15, 8), constrained_layout=True)\n",
    "fig.suptitle('Class Accuracies per Fold', fontsize=16)\n",
    "\n",
    "for class_idx in range(num_classes):\n",
    "    row = class_idx // 5\n",
    "    col = class_idx % 5\n",
    "    ax = axs[row, col]\n",
    "    \n",
    "    # Accuracies de cada fold para la clase actual\n",
    "    accuracies_per_fold = class_accuracies_val[:, class_idx]\n",
    "    \n",
    "    # Asignar un color único a todas las barras del subplot (un color distinto por subplot)\n",
    "    color_option = cmap(class_idx % 10)\n",
    "    \n",
    "    # Mismo color para todas las barras en el subplot, pero distinto para cada clase\n",
    "    ax.bar(range(1, num_folds + 1), accuracies_per_fold, color=color_option, edgecolor='black')\n",
    "    \n",
    "    # Línea de promedio\n",
    "    avg_accuracy = mean_class_accuracies_val[class_idx]\n",
    "    ax.axhline(y=avg_accuracy, color='black', linestyle='--', label=f'Avg: {avg_accuracy:.2f}', linewidth=2)\n",
    "    \n",
    "    # Usar el mapeo para el título de cada clase\n",
    "    class_name = class_mapping.get(class_idx, f'Class {class_idx}')\n",
    "    ax.set_title(class_name)\n",
    "    ax.set_xlabel('Fold')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(num_classes), mean_class_accuracies_val, color=colors, edgecolor='black')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Accuracy per Class across Folds')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Usar el mapeo para mostrar los nombres de las clases en el eje x\n",
    "class_labels = [class_mapping.get(i, f'Class {i}') for i in range(num_classes)]\n",
    "plt.xticks(range(num_classes), class_labels, rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reportes de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Validation Classification Report per Fold with Overall Metrics:\")\n",
    "\n",
    "for fold_result in folds_performance:\n",
    "    print(f\"\\nFold {fold_result['fold']} - Validation Classification Report:\")\n",
    "    val_report = fold_result['val_report']\n",
    "    \n",
    "    # Mostrar métricas por clase solo con el nombre de la clase\n",
    "    for label, metrics in val_report.items():\n",
    "        if label.isdigit():  # Solo mostrar métricas por clase\n",
    "            class_name = class_mapping.get(int(label), \"Unknown Class\")  # Obtener nombre de la clase\n",
    "            print(f\"{class_name}: Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1-score']:.4f}\")\n",
    "    \n",
    "    # Mostrar métricas generales\n",
    "    if 'macro avg' in val_report:\n",
    "        general_metrics = val_report['macro avg']\n",
    "        print(\"\\nGeneral Metrics (Macro Average):\")\n",
    "        print(f\"Precision: {general_metrics['precision']:.4f}, Recall: {general_metrics['recall']:.4f}, F1-Score: {general_metrics['f1-score']:.4f}\")\n",
    "    elif 'weighted avg' in val_report:\n",
    "        general_metrics = val_report['weighted avg']\n",
    "        print(\"\\nGeneral Metrics (Weighted Average):\")\n",
    "        print(f\"Precision: {general_metrics['precision']:.4f}, Recall: {general_metrics['recall']:.4f}, F1-Score: {general_metrics['f1-score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historico de Perdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el número de épocas (asumiendo que todos los folds tienen la misma cantidad de épocas)\n",
    "num_epochs = len(folds_performance[0]['train_losses'])\n",
    "\n",
    "# Inicializar arrays para acumular las pérdidas de entrenamiento y validación\n",
    "avg_train_losses = np.zeros(num_epochs)\n",
    "avg_val_losses = np.zeros(num_epochs)\n",
    "\n",
    "# Acumular las pérdidas de cada fold\n",
    "for fold_result in folds_performance:\n",
    "    avg_train_losses += np.array(fold_result['train_losses'])\n",
    "    avg_val_losses += np.array(fold_result['val_losses'])\n",
    "\n",
    "# Calcular el promedio dividiendo por el número de folds\n",
    "avg_train_losses /= len(folds_performance)\n",
    "avg_val_losses /= len(folds_performance)\n",
    "\n",
    "# Crear los subplots para cada fold\n",
    "fig, axs = plt.subplots(2, 5, figsize=(16, 8), constrained_layout=True)\n",
    "fig.suptitle('Train and Validation Loss per Epoch for Each Fold', fontsize=16)\n",
    "\n",
    "for i, fold_result in enumerate(folds_performance):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    ax = axs[row, col]\n",
    "    \n",
    "    # Extraer pérdidas de entrenamiento y validación\n",
    "    train_losses = fold_result['train_losses']\n",
    "    val_losses = fold_result['val_losses']\n",
    "    \n",
    "    # Graficar las pérdidas en el subplot correspondiente\n",
    "    ax.plot(train_losses, label='Train Loss')\n",
    "    ax.plot(val_losses, label='Validation Loss')\n",
    "    ax.set_title(f'Fold {fold_result[\"fold\"]}')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico adicional para las pérdidas promedio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_train_losses, label='Average Train Loss', color='blue')\n",
    "plt.plot(avg_val_losses, label='Average Validation Loss', color='orange')\n",
    "plt.title('Average Train and Validation Loss per Epoch Across Folds')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Historico de Precisiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el número de épocas (asumiendo que todos los folds tienen la misma cantidad de épocas)\n",
    "num_epochs = len(folds_performance[0]['train_accuracies'])\n",
    "\n",
    "# Inicializar arrays para acumular las precisiones de entrenamiento y validación\n",
    "avg_train_accuracies = np.zeros(num_epochs)\n",
    "avg_val_accuracies = np.zeros(num_epochs)\n",
    "\n",
    "# Acumular las precisiones de cada fold\n",
    "for fold_result in folds_performance:\n",
    "    avg_train_accuracies += np.array(fold_result['train_accuracies'])\n",
    "    avg_val_accuracies += np.array(fold_result['val_accuracies'])\n",
    "\n",
    "# Calcular el promedio dividiendo por el número de folds\n",
    "avg_train_accuracies /= len(folds_performance)\n",
    "avg_val_accuracies /= len(folds_performance)\n",
    "\n",
    "# Crear los subplots para cada fold\n",
    "fig, axs = plt.subplots(2, 5, figsize=(16, 8), constrained_layout=True)\n",
    "fig.suptitle('Train and Validation Accuracy per Epoch for Each Fold', fontsize=16)\n",
    "\n",
    "for i, fold_result in enumerate(folds_performance):\n",
    "    row = i // 5\n",
    "    col = i % 5\n",
    "    ax = axs[row, col]\n",
    "    \n",
    "    # Extraer precisiones de entrenamiento y validación\n",
    "    train_accuracies = fold_result['train_accuracies']\n",
    "    val_accuracies = fold_result['val_accuracies']\n",
    "    \n",
    "    # Graficar las precisiones en el subplot correspondiente\n",
    "    ax.plot(train_accuracies, label='Train Accuracy')\n",
    "    ax.plot(val_accuracies, label='Validation Accuracy')\n",
    "    ax.set_title(f'Fold {fold_result[\"fold\"]}')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico adicional para las precisiones promedio\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_train_accuracies, label='Average Train Accuracy', color='blue')\n",
    "plt.plot(avg_val_accuracies, label='Average Validation Accuracy', color='orange')\n",
    "plt.title('Average Train and Validation Accuracy per Epoch Across Folds')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar una matriz para acumular las matrices de confusión de validación\n",
    "num_classes = folds_performance[0]['val_matrix'].shape[0]\n",
    "avg_conf_matrix = np.zeros((num_classes, num_classes), dtype=float)\n",
    "\n",
    "# Acumular las matrices de confusión de cada fold\n",
    "for fold_result in folds_performance:\n",
    "    avg_conf_matrix += fold_result['val_matrix']\n",
    "\n",
    "# Calcular el promedio dividiendo por el número de folds\n",
    "avg_conf_matrix /= len(folds_performance)\n",
    "\n",
    "# Obtener las etiquetas de clase usando el mapeo\n",
    "class_labels = [class_mapping[i] for i in range(num_classes)]\n",
    "\n",
    "# Graficar la matriz de confusión promedio\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(avg_conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.title(\"Average Validation Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoundClassifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
